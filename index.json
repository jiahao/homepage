[{"authors":["jiahao"],"categories":null,"content":"Jiahao Chen is a Vice President and Research Lead at JPMorgan AI Research in New York, with research focusing on explainability and fairness in machine learning, as well as semantic knowledge management. He was previously a Senior Manager of Data Science at Capital One focusing on machine learning research for credit analytics and retail operations.\nWhen still in academia, Jiahao was a Research Scientist at MIT CSAIL where he co-founded and led the Julia Lab, focusing on applications of the Julia programming language to data science, scientific computing, and machine learning. Jiahao has organized JuliaCon, the Julia conference, for the years 2014-2016, as well as organized workshops at NeurIPS, SIAM CSE, and the American Chemical Society National Meetings. Jiahao has authored over 120 packages for numerical computation, data science and machine learning for the Julia programming language, in addition to numerous contributions to the base language itself.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"d4664b440d4c100876521e8855483c43","permalink":"https://jiahao.github.io/authors/jiahao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jiahao/","section":"authors","summary":"Jiahao Chen is a Vice President and Research Lead at JPMorgan AI Research in New York, with research focusing on explainability and fairness in machine learning, as well as semantic knowledge management. He was previously a Senior Manager of Data Science at Capital One focusing on machine learning research for credit analytics and retail operations.\nWhen still in academia, Jiahao was a Research Scientist at MIT CSAIL where he co-founded and led the Julia Lab, focusing on applications of the Julia programming language to data science, scientific computing, and machine learning.","tags":null,"title":"Jiahao Chen","type":"authors"},{"authors":[],"categories":[],"content":"I am a core contributor to the Julia programming language. In addition to starting and running the Julia Lab at MIT CSAIL from 2013\u0026mdash;2017, I have also made over 500 commits to the core Julia repository, and authored over 80 Julia packages spread over the JuliaMatrices, JuliaMath, JuliaParallel, JuliaQuantum, JuliaSparse, JuliaStats, and JuliaText organizations, and also my personal account. I am also involved in the JuliaCN documentation translation efforts into Mandarin Chinese, the JuliaCon organizing committee (including chairing the first three JuliaCons 2014\u0026mdash;2016), and broader outreach efforts through the NumFOCUS nonprofit.\n","date":1574239357,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574239357,"objectID":"21c07d8624497a6d97f3baa4e7183c57","permalink":"https://jiahao.github.io/project/julia/","publishdate":"2019-11-20T16:42:37+08:00","relpermalink":"/project/julia/","section":"project","summary":"I am a core contributor to the Julia programming language. In addition to starting and running the Julia Lab at MIT CSAIL from 2013\u0026mdash;2017, I have also made over 500 commits to the core Julia repository, and authored over 80 Julia packages spread over the JuliaMatrices, JuliaMath, JuliaParallel, JuliaQuantum, JuliaSparse, JuliaStats, and JuliaText organizations, and also my personal account. I am also involved in the JuliaCN documentation translation efforts into Mandarin Chinese, the JuliaCon organizing committee (including chairing the first three JuliaCons 2014\u0026mdash;2016), and broader outreach efforts through the NumFOCUS nonprofit.","tags":[],"title":"Julia","type":"project"},{"authors":["Jiahao Chen","Nathan Kallus","Xiaojie Mao","Geoffry Svacha","Madeleine Udell"],"categories":null,"content":"My intern, Xiaojie Mao, will be presenting his summer research work while at Capital One.\n","date":1547823375,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547823375,"objectID":"cd99cfecebc73588754700e152fd4fb6","permalink":"https://jiahao.github.io/talk/2019-fatstar/","publishdate":"2019-01-18T09:56:15-05:00","relpermalink":"/talk/2019-fatstar/","section":"talk","summary":"My intern, Xiaojie Mao, will be presenting his summer research work while at Capital One.","tags":[],"title":"Fairness under unawareness: assessing disparity when protected class is unobserved","type":"talk"},{"authors":["Jiahao Chen","Nathan Kallus","Xiaojie Mao","Geoffry Svacha","Madeleine Udell"],"categories":null,"content":"","date":1543334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543334400,"objectID":"0d215271a0e226c60ae93aeb6a35f81d","permalink":"https://jiahao.github.io/publication/chen-2019-fatstar/","publishdate":"2018-11-28T00:00:00+08:00","relpermalink":"/publication/chen-2019-fatstar/","section":"publication","summary":"Assessing the fairness of a decision making system with respect to a protected class, such as gender or race, is challenging when class membership labels are unavailable. Probabilistic models for predicting the protected class based on observable proxies, such as surname and geolocation for race, are sometimes used to impute these missing labels for compliance assessments. Empirically, these methods are observed to exaggerate disparities, but the reason why is unknown. In this paper, we decompose the biases in estimating outcome disparity via threshold-based imputation into multiple interpretable bias sources, allowing us to explain when over- or underestimation occurs. We also propose an alternative weighted estimator that uses soft classification, and show that its bias arises simply from the conditional covariance of the outcome with the true class membership. Finally, we illustrate our results with numerical simulations and a public dataset of mortgage applications, using geolocation as a proxy for race. We confirm that the bias of threshold-based imputation is generally upward, but its magnitude varies strongly with the threshold chosen. Our new weighted estimator tends to have a negative bias that is much simpler to analyze and reason about.","tags":null,"title":"Fairness under unawareness: disparate impact evaluation with proxy for unknown protected attribute","type":"publication"},{"authors":["Jiahao Chen"],"categories":null,"content":"","date":1538838156,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538838156,"objectID":"2cd5f888cc8fc7a32f8e731e523aadd3","permalink":"https://jiahao.github.io/talk/2018-fatrec/","publishdate":"2018-10-06T10:02:36-05:00","relpermalink":"/talk/2018-fatrec/","section":"talk","summary":"The financial services industry has unique explainability and fairness challenges arising from compliance and ethical considerations in credit decisioning. These challenges complicate the use of model machine learning and artificial intelligence methods in business decision processes.","tags":[],"title":"Fair Lending Needs Explainable Models for Responsible Recommendation","type":"talk"},{"authors":["Jiahao Chen"],"categories":null,"content":"","date":1536681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536681600,"objectID":"1bf599f8c2eb94d523c3a76d08fd8c06","permalink":"https://jiahao.github.io/publication/chen-2018-fatrec/","publishdate":"2018-09-12T00:00:00+08:00","relpermalink":"/publication/chen-2018-fatrec/","section":"publication","summary":"The financial services industry has unique explainability and fairness challenges arising from compliance and ethical considerations in credit decisioning. These challenges complicate the use of model machine learning and artificial intelligence methods in business decision processes.","tags":null,"title":"Fair lending needs explainable models for responsible recommendation","type":"publication"}]